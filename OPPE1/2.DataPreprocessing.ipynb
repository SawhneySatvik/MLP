{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feaure Extraction\n",
    "- Dictionary Vectorizer - Converts lists of mappings of feature name and feature value into a matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        'age':4, \"height\":96.0\n",
    "    },\n",
    "    {\n",
    "        'age':6, \"height\":108.0\n",
    "    },\n",
    "    {\n",
    "        'age':9, \"height\":173.0\n",
    "    },\n",
    "    {\n",
    "        'age':10, \"height\":54.0\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dv = DictVectorizer(sparse=False)\n",
    "vectorized_data = dv.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.  96.]\n",
      " [  6. 108.]\n",
      " [  9. 173.]\n",
      " [ 10.  54.]]\n",
      "<class 'numpy.ndarray'>\n",
      "[{'age': 4, 'height': 96.0}, {'age': 6, 'height': 108.0}, {'age': 9, 'height': 173.0}, {'age': 10, 'height': 54.0}]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(vectorized_data)\n",
    "print(type(vectorized_data))\n",
    "print(data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'age': np.float64(4.0), 'height': np.float64(96.0)}, {'age': np.float64(6.0), 'height': np.float64(108.0)}, {'age': np.float64(9.0), 'height': np.float64(173.0)}, {'age': np.float64(10.0), 'height': np.float64(54.0)}]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "data_back = dv.inverse_transform(vectorized_data)\n",
    "print(data_back)\n",
    "print(type(data_back))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "- Simple Imputer - Fills missing values with one of the following stratergies\n",
    "- - mean\n",
    "- - median\n",
    "- - most_frequesnt\n",
    "- - constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.  1.]\n",
      " [nan  8.]\n",
      " [ 2. nan]\n",
      " [ 9.  6.]]\n"
     ]
    }
   ],
   "source": [
    "matrix = np.array([[7, 1],[np.nan, 8], [2, np.nan], [9,6]])\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "si_mean = SimpleImputer(strategy=\"mean\")\n",
    "si_median = SimpleImputer(strategy=\"median\")\n",
    "si_most_frequent = SimpleImputer(strategy=\"most_frequent\")\n",
    "si_constant = SimpleImputer(strategy=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7. 1.]\n",
      " [6. 8.]\n",
      " [2. 5.]\n",
      " [9. 6.]]\n"
     ]
    }
   ],
   "source": [
    "matrix_mean = si_mean.fit_transform(matrix)\n",
    "print(matrix_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7. 1.]\n",
      " [7. 8.]\n",
      " [2. 6.]\n",
      " [9. 6.]]\n"
     ]
    }
   ],
   "source": [
    "matrix_median = si_median.fit_transform(matrix)\n",
    "print(matrix_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7. 1.]\n",
      " [2. 8.]\n",
      " [2. 1.]\n",
      " [9. 6.]]\n"
     ]
    }
   ],
   "source": [
    "matrix_most_frequent = si_most_frequent.fit_transform(matrix)\n",
    "print(matrix_most_frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2. nan]\n",
      " [ 3.  4.  3.]\n",
      " [nan  6.  5.]\n",
      " [ 8.  8.  7.]]\n"
     ]
    }
   ],
   "source": [
    "matrix_KNN = np.array([[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, 7]])\n",
    "print(matrix_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 5.]\n",
      " [3. 4. 3.]\n",
      " [4. 6. 5.]\n",
      " [8. 8. 7.]]\n"
     ]
    }
   ],
   "source": [
    "knni = KNNImputer()\n",
    "\n",
    "matrix_knn_transformed = knni.fit_transform(matrix_KNN)\n",
    "\n",
    "print(matrix_knn_transformed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  2.  4. ]\n",
      " [3.  4.  3. ]\n",
      " [5.5 6.  5. ]\n",
      " [8.  8.  7. ]]\n"
     ]
    }
   ],
   "source": [
    "knni2 = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "\n",
    "matrix_knn_transformed2 = knni2.fit_transform(matrix_KNN)\n",
    "\n",
    "print(matrix_knn_transformed2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4]\n",
      " [3]\n",
      " [2]\n",
      " [5]\n",
      " [6]]\n"
     ]
    }
   ],
   "source": [
    "X_S = np.array([[4,], [3,], [2,], [5,], [6,]])\n",
    "print(X_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        ]\n",
      " [-0.70710678]\n",
      " [-1.41421356]\n",
      " [ 0.70710678]\n",
      " [ 1.41421356]]\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "new_X_SS = ss.fit_transform(X_S)\n",
    "print(new_X_SS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
